---
title: "Getting Started with Tidymodels"
author: "Mikhael Dito Manurung"
date: '2020-02-29'
slug: getting-started-with-tidymodels
tags:
- R
- tidymodels
- machine learning
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<pre class="r"><code>knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  cache = TRUE,
  fig.width = 6,
  fig.height = 6,
  dpi = 320,
  tidy.opts = list(width.cutoff = 50)
)</code></pre>
<p><code>tidymodels</code> is a new R metapackage that will tidy up your machine learning workflow. Max Kuhn, the creator of the famous <code>caret</code>, also leads the development of this package. Compared to other machine learning packages in R, such as <code>caret</code> or <code>mlr</code>, <code>tidymodels</code> is still under development. However, it seems to me that the <code>tidymodels</code> framework has started to taking up shape. So, if you are still new to R and wants to learn machine learning with R, I would suggest to learn the <code>tidymodels</code>. Unfortunately, <code>tidymodels</code> tutorials are still scarce due to its very young age. I believe that this scarcity may change very soon. So, let us get started on the basic workflow of machine learning with <code>tidymodels</code>.</p>
<div id="getting-started" class="section level2">
<h2>Getting Started</h2>
<p><a href="https://github.com/tidymodels/tidymodels"><code>tidymodels</code></a> is a collection of R packages (i.e. metapackage) for modeling and statistical analysis. Every package in this framework serves a particular purpose. I would not recommend reading through the documentations of all packages within the <code>tidymodels</code> framework as it could be quite overwhelming. Indeed, tidymodels give you a very different experience compared to with <code>caret</code> that contains everything within the package. So, I will introduce you to the core packages of <code>tidymodels</code> that will be used frequently. Let us start with <a href="https://tidymodels.github.io/parsnip/"><code>parsnip</code></a>.</p>
</div>
<div id="specify-your-model" class="section level2">
<h2>Specify your model</h2>
<p><code>parsnip</code> provides a uniform interface to specify model or algorithm that you want to fit to your data. All available models are listed <a href="https://tidymodels.github.io/parsnip/articles/articles/Models.html">here</a>.</p>
<p>Basic steps:
1. Pick a <strong>model</strong>
2. Set the <strong>engine</strong>
3. Set the <strong>mode</strong> (if needed)</p>
<pre class="r"><code># library(parsnip)
# glm_spec &lt;- 
#   logistic_reg() %&gt;% 
#   set_engine(&quot;glm&quot;)</code></pre>
</div>
<div id="split-your-data" class="section level2">
<h2>Split your data</h2>
<pre class="r"><code># library(rsample)
# set.seed(1234)
# 
# pima &lt;- read.csv(&quot;&quot;)
# 
# pima_split &lt;- initial_split(pima, prop = 0.8, strata = Outcome)
# 
# pima_training &lt;- training(pima_split)
# pima_testing &lt;- testing(pima_split)</code></pre>
<pre class="r"><code># fit_split &lt;- function(formula, model, split, ...) {
#   wf &lt;- workflows::add_model(workflows::add_formula(workflows::workflow(), formula, blueprint = hardhat::default_formula_blueprint(indicators = FALSE)), model)
#   tune::last_fit(wf, split, ...)
# }</code></pre>
</div>
<div id="fit-your-model" class="section level2">
<h2>Fit your model</h2>
<pre class="r"><code># glm_fit &lt;- fit_split(
#   Outcome ~ ., # declare the formula
#   model = glm_spec,
#   split = pima_split,
#   metrics = metric_set(accuracy, sens, spec)
# )
# 
# head(glm_fit)</code></pre>
<pre class="r"><code># glm_fit %&gt;% 
#   unnest(.predictions)</code></pre>
<pre class="r"><code># glm_fit %&gt;% 
#   collect_predictions()</code></pre>
<pre class="r"><code># glm_fit %&gt;% 
#   collect_predictions() %&gt;% 
#   count(truth = Outcome, estimate = .pred_class)</code></pre>
<pre class="r"><code># glm_fit %&gt;% 
#   collect_predictions() %&gt;% 
#   conf_mat(truth = Outcome, estimate = .pred_class)</code></pre>
<pre class="r"><code># glm_fit %&gt;% 
#   collect_predictions() %&gt;% 
#   conf_mat(truth = Outcome, estimate = .pred_class) %&gt;% 
#   autoplot(type = &quot;heatmap&quot;)</code></pre>
</div>
<div id="evaluate-your-model" class="section level2">
<h2>Evaluate your model</h2>
<p>Remember, the diagonals are the correct predictions!</p>
<p>In most cases, confusion matrix is enough for evaluating model performance. However, when you are comparing many models simultaneously, you would want the information to be compressed into a single number.</p>
<div id="accuracy" class="section level3">
<h3>Accuracy</h3>
</div>
<div id="specificity" class="section level3">
<h3>Specificity</h3>
</div>
<div id="sensitivity" class="section level3">
<h3>Sensitivity</h3>
<pre class="r"><code># glm_fit %&gt;% 
#   collect_metrics()</code></pre>
</div>
<div id="roc-curve" class="section level3">
<h3>ROC Curve</h3>
<pre class="r"><code># glm_fit %&gt;% 
#   collect_predictions() %&gt;% 
#   roc_curve(truth = Outcome, estimate = .pred_Outcome)</code></pre>
<p>That’s it! What if you want to fit a decision tree instead? You just have to specify a new model:</p>
<pre class="r"><code># dt_spec &lt;- 
#   decision_tree() %&gt;% 
#   set_engine(&quot;C5.0&quot;)</code></pre>
<p>And then plug it into where we put <code>glm_spec</code> before.</p>
<pre class="r"><code># Doing everything in one go
# fit_split(
#   Outcome ~ ., 
#   model = dt_spec, # just change this line
#   split = pima_split,
#   metrics = metric_set(accuracy, sens, spec)) %&gt;% 
#   collect_metrics()</code></pre>
<p>Very simple, or should I say, tidy.</p>
<p>In the upcoming post, I will discuss how to fit and evaluate multiple models so that we can pick the best one for our purpose. Until next time!</p>
</div>
</div>
